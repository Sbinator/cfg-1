Automatically generated by Mendeley Desktop 1.17.6
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Clune2011,
abstract = {This paper introduces an algorithm for evolving 3D objects with a generative encoding that abstracts how biological morphologies are produced. Evolving interesting 3D objects is useful in many disciplines, including artistic design (e.g. sculpture), engineering (e.g. robotics, architecture, or product design), and biology (e.g. for investigating morphological evolution). A critical element in evolving 3D objects is the representation, which strongly influences the types of objects produced. In 2007 a representation was introduced called Compositional Pattern Producing Networks (CPPN), which abstracts how natural phenotypes are generated. To date, however, the ability of CPPNs to create 3D objects has barely been explored. Here we present a new way to create 3D objects with CPPNs. Experiments with both interactive and target-based evolution demonstrate that CPPNs show potential in generating interesting, complex, 3D objects. We further show that changing the information provided to CPPNs and the functions allowed in their genomes biases the types of objects produced. Finally, we validate that the objects transfer well from simulation to the real-world by printing them with a 3D printer. Overall, this paper shows that evolving objects with encodings based on concepts from biological development can be a powerful way to evolve complex, interesting objects, which should be of use in fields as diverse as art, engineering, and biology.},
author = {Clune, Jeff and Lipson, Hod},
doi = {10.1145/2078245.2078246},
issn = {19318499},
journal = {ACM SIGEVOlution},
number = {4},
pages = {2--12},
title = {{Evolving 3D objects with a generative encoding inspired by developmental biology}},
volume = {5},
year = {2011}
}
@article{Koutnik2010,
abstract = {We propose a new indirect encoding scheme for neural networks in which the weight matrices are represented in the frequency domain by sets Fourier coefficients. This scheme exploits spatial regularities in the matrix to reduce the dimensionality of the representation by ignoring high-frequency coefficients, as is done in lossy image compression. We compare the efficiency of searching in this "compressed" network space to searching in the space of directly encoded networks, using the CoSyNE neuroevolution algorithm on three benchmark problems: pole-balancing, ball throwing and octopus arm control. The results show that this encoding can dramatically reduce the search space dimensionality such that solutions can be found in significantly fewer evaluations.},
author = {Koutn{\'{i}}k, Jan and Gomez, Faustino and Schmidhuber, J{\"{u}}rgen},
doi = {10.1145/1830483.1830596},
isbn = {9781450300728},
issn = {9781450300728},
journal = {Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation - GECCO '10},
keywords = {evolutionary algorithms,indirect encoding,neuroevolution,recurrent neural networks},
pages = {619},
title = {{Evolving Neural Networks in Compressed Weight Space}},
url = {http://portal.acm.org/citation.cfm?id=1830483.1830596},
year = {2010}
}
@article{Clune2011,
abstract = {This paper introduces an algorithm for evolving 3D objects with a generative encoding that abstracts how biological morphologies are produced. Evolving interesting 3D objects is useful in many disciplines, including artistic design (e.g. sculpture), engineering (e.g. robotics, architecture, or product design), and biology (e.g. for investigating morphological evolution). A critical element in evolving 3D objects is the representation, which strongly influences the types of objects produced. In 2007 a representation was introduced called Compositional Pattern Producing Networks (CPPN), which abstracts how natural phenotypes are generated. To date, however, the ability of CPPNs to create 3D objects has barely been explored. Here we present a new way to create 3D objects with CPPNs. Experiments with both interactive and target-based evolution demonstrate that CPPNs show potential in generating interesting, complex, 3D objects. We further show that changing the information provided to CPPNs and the functions allowed in their genomes biases the types of objects produced. Finally, we validate that the objects transfer well from simulation to the real-world by printing them with a 3D printer. Overall, this paper shows that evolving objects with encodings based on concepts from biological development can be a powerful way to evolve complex, interesting objects, which should be of use in fields as diverse as art, engineering, and biology.},
author = {Clune, Jeff and Lipson, Hod},
doi = {10.1145/2078245.2078246},
issn = {19318499},
journal = {ACM SIGEVOlution},
number = {4},
pages = {2--12},
title = {{Evolving 3D objects with a generative encoding inspired by developmental biology}},
volume = {5},
year = {2011}
}
@article{Ha2016,
abstract = {This work explores hypernetworks: an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype - the hypernetwork - and a phenotype - the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve state-of-art results on a variety of language modeling tasks with Character-Level Penn Treebank and Hutter Prize Wikipedia datasets, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters.},
archivePrefix = {arXiv},
arxivId = {1609.09106},
author = {Ha, David and Dai, Andrew and Le, Quoc V},
eprint = {1609.09106},
file = {:home/lepisma/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ha, Dai, Le - 2016 - HyperNetworks.pdf:pdf},
title = {{HyperNetworks}},
url = {http://arxiv.org/abs/1609.09106},
year = {2016}
}
@article{Koutnik2010,
abstract = {We propose a new indirect encoding scheme for neural networks in which the weight matrices are represented in the frequency domain by sets Fourier coefficients. This scheme exploits spatial regularities in the matrix to reduce the dimensionality of the representation by ignoring high-frequency coefficients, as is done in lossy image compression. We compare the efficiency of searching in this "compressed" network space to searching in the space of directly encoded networks, using the CoSyNE neuroevolution algorithm on three benchmark problems: pole-balancing, ball throwing and octopus arm control. The results show that this encoding can dramatically reduce the search space dimensionality such that solutions can be found in significantly fewer evaluations.},
author = {Koutn{\'{i}}k, Jan and Gomez, Faustino and Schmidhuber, J{\"{u}}rgen},
doi = {10.1145/1830483.1830596},
isbn = {9781450300728},
issn = {9781450300728},
journal = {Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation - GECCO '10},
keywords = {evolutionary algorithms,indirect encoding,neuroevolution,recurrent neural networks},
pages = {619},
title = {{Evolving Neural Networks in Compressed Weight Space}},
url = {http://portal.acm.org/citation.cfm?id=1830483.1830596},
year = {2010}
}
@article{DeBrabandere2016,
abstract = {In a traditional convolutional layer, the learned filters stay fixed after training. In contrast, we introduce a new framework, the Dynamic Filter Network, where filters are generated dynamically conditioned on an input. We show that this architecture is a powerful one, with increased flexibility thanks to its adaptive nature, yet without an excessive increase in the number of model parameters. A wide variety of filtering operations can be learned this way, including local spatial transformations, but also others like selective (de)blurring or adaptive feature extraction. Moreover, multiple such layers can be combined, e.g. in a recurrent architecture. We demonstrate the effectiveness of the dynamic filter network on the tasks of video and stereo prediction, and reach state-of-the-art performance on the moving MNIST dataset with a much smaller model. By visualizing the learned filters, we illustrate that the network has picked up flow information by only looking at unlabelled training data. This suggests that the network can be used to pretrain networks for various supervised tasks in an unsupervised way, like optical flow and depth estimation.},
annote = {Papers to read:
1. Patraucean et al. [17]
2. Shi et: convolutional LSTM},
archivePrefix = {arXiv},
arxivId = {1605.09673},
author = {{De Brabandere}, Bert and Jia, Xu and Tuytelaars, Tinne and {Van Gool}, Luc},
eprint = {1605.09673},
file = {:home/lepisma/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Brabandere et al. - 2016 - Dynamic Filter Networks.pdf:pdf},
journal = {CoRR},
month = {may},
pages = {1--14},
title = {{Dynamic Filter Networks}},
url = {http://arxiv.org/abs/1605.09673},
year = {2016}
}
@article{Fernando2016,
abstract = {Data represented as strings abounds in biology, linguistics, document mining, web search and many other fields. Such data often have a hierarchical structure, either because they were artificially designed and composed in a hierarchical manner or because there is an underlying evolutionary process that creates repeatedly more complex strings from simpler substrings. We propose a framework, referred to as "Lexis", that produces an optimized hierarchical representation of a given set of "target" strings. The resulting hierarchy, "Lexis-DAG", shows how to construct each target through the concatenation of intermediate substrings, minimizing the total number of such concatenations or DAG edges. The Lexis optimization problem is related to the smallest grammar problem. After we prove its NP-Hardness for two cost formulations, we propose an efficient greedy algorithm for the construction of Lexis-DAGs. We also consider the problem of identifying the set of intermediate nodes (substrings) that collectively form the "core" of a Lexis-DAG, which is important in the analysis of Lexis-DAGs. We show that the Lexis framework can be applied in diverse applications such as optimized synthesis of DNA fragments in genomic libraries, hierarchical structure discovery in protein sequences, dictionary-based text compression, and feature extraction from a set of documents.},
archivePrefix = {arXiv},
arxivId = {arXiv:1602.05561v1},
author = {Fernando, Chrisantha and Banarse, Dylan and Reynolds, Malcolm and Besse, Frederic and Pfau, David and Jaderberg, Max and Lanctot, Marc and Wierstra, Daan},
doi = {10.1145/2908812.2908890},
eprint = {arXiv:1602.05561v1},
file = {:home/lepisma/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fernando et al. - 2016 - Convolution by Evolution.pdf:pdf},
isbn = {9781450342063},
journal = {Proceedings of the 2016 on Genetic and Evolutionary Computation Conference - GECCO '16},
keywords = {compositional pattern producing networks,cppns,de-,mnist,noising autoencoder},
pages = {109--116},
title = {{Convolution by Evolution}},
year = {2016}
}
@article{Stanley2002,
abstract = {The ventral visual pathway implements object recognition and categorization in a hierarchy of processing areas with neuronal selectivities of increasing complexity. The presence of massive feedback connections within this hierarchy raises the possibility that normal visual processing relies on the use of computational loops. It is not known, however, whether object recognition can be performed at all without such loops (i.e., in a purely feed-forward mode). By analyzing the time course of reaction times in a masked natural scene categorization paradigm, we show that the human visual system can generate selective motor responses based on a single feed-forward pass. We confirm these results using a more constrained letter discrimination task, in which the rapid succession of a target and mask is actually perceived as a distractor. We show that a masked stimulus presented for only 26 msecand often not consciously perceivedcan fully determine the earliest selective motor responses: The neural representations of the stimulus and mask are thus kept separated during a short period corresponding to the feedforward sweep. Therefore, feedback loops do not appear to be mandatory for visual processing. Rather, we found that such loops allow the masked stimulus to reverberate in the visual system and affect behavior for nearly 150 msec after the feed-forward sweep.},
author = {Stanley, Kenneth O. and Miikkulainen, Risto},
doi = {10.1162/106365602320169811},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary Computation},
number = {2},
pages = {99--127},
pmid = {12180173},
title = {{Evolving Neural Networks through Augmenting Topologies}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089892903321208141{\%}5Cnhttp://www.mitpressjournals.org/doi/abs/10.1162/106365602320169811},
volume = {10},
year = {2002}
}
@article{Fernando2016,
abstract = {Data represented as strings abounds in biology, linguistics, document mining, web search and many other fields. Such data often have a hierarchical structure, either because they were artificially designed and composed in a hierarchical manner or because there is an underlying evolutionary process that creates repeatedly more complex strings from simpler substrings. We propose a framework, referred to as "Lexis", that produces an optimized hierarchical representation of a given set of "target" strings. The resulting hierarchy, "Lexis-DAG", shows how to construct each target through the concatenation of intermediate substrings, minimizing the total number of such concatenations or DAG edges. The Lexis optimization problem is related to the smallest grammar problem. After we prove its NP-Hardness for two cost formulations, we propose an efficient greedy algorithm for the construction of Lexis-DAGs. We also consider the problem of identifying the set of intermediate nodes (substrings) that collectively form the "core" of a Lexis-DAG, which is important in the analysis of Lexis-DAGs. We show that the Lexis framework can be applied in diverse applications such as optimized synthesis of DNA fragments in genomic libraries, hierarchical structure discovery in protein sequences, dictionary-based text compression, and feature extraction from a set of documents.},
archivePrefix = {arXiv},
arxivId = {arXiv:1602.05561v1},
author = {Fernando, Chrisantha and Banarse, Dylan and Reynolds, Malcolm and Besse, Frederic and Pfau, David and Jaderberg, Max and Lanctot, Marc and Wierstra, Daan},
doi = {10.1145/2908812.2908890},
eprint = {arXiv:1602.05561v1},
file = {:home/lepisma/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fernando et al. - 2016 - Convolution by Evolution.pdf:pdf},
isbn = {9781450342063},
journal = {Proceedings of the 2016 on Genetic and Evolutionary Computation Conference - GECCO '16},
keywords = {compositional pattern producing networks,cppns,de-,mnist,noising autoencoder},
pages = {109--116},
title = {{Convolution by Evolution}},
year = {2016}
}
@article{Stanley2002,
abstract = {The ventral visual pathway implements object recognition and categorization in a hierarchy of processing areas with neuronal selectivities of increasing complexity. The presence of massive feedback connections within this hierarchy raises the possibility that normal visual processing relies on the use of computational loops. It is not known, however, whether object recognition can be performed at all without such loops (i.e., in a purely feed-forward mode). By analyzing the time course of reaction times in a masked natural scene categorization paradigm, we show that the human visual system can generate selective motor responses based on a single feed-forward pass. We confirm these results using a more constrained letter discrimination task, in which the rapid succession of a target and mask is actually perceived as a distractor. We show that a masked stimulus presented for only 26 msecand often not consciously perceivedcan fully determine the earliest selective motor responses: The neural representations of the stimulus and mask are thus kept separated during a short period corresponding to the feedforward sweep. Therefore, feedback loops do not appear to be mandatory for visual processing. Rather, we found that such loops allow the masked stimulus to reverberate in the visual system and affect behavior for nearly 150 msec after the feed-forward sweep.},
author = {Stanley, Kenneth O. and Miikkulainen, Risto},
doi = {10.1162/106365602320169811},
isbn = {1063-6560},
issn = {1063-6560},
journal = {Evolutionary Computation},
number = {2},
pages = {99--127},
pmid = {12180173},
title = {{Evolving Neural Networks through Augmenting Topologies}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089892903321208141{\%}5Cnhttp://www.mitpressjournals.org/doi/abs/10.1162/106365602320169811},
volume = {10},
year = {2002}
}
@article{Stanley2009,
abstract = {Research in neuroevolution-that is, evolving artificial neural networks (ANNs) through evolutionary algorithms-is inspired by the evolution of biological brains, which can contain trillions of connections. Yet while neuroevolution has produced successful results, the scale of natural brains remains far beyond reach. This article presents a method called hypercube-based NeuroEvolution of Augmenting Topologies (HyperNEAT) that aims to narrow this gap. HyperNEAT employs an indirect encoding called connective compositional pattern-producing networks (CPPNs) that can produce connectivity patterns with symmetries and repeating motifs by interpreting spatial patterns generated within a hypercube as connectivity patterns in a lower-dimensional space. This approach can exploit the geometry of the task by mapping its regularities onto the topology of the network, thereby shifting problem difficulty away from dimensionality to the underlying problem structure. Furthermore, connective CPPNs can represent the same connectivity pattern at any resolution, allowing ANNs to scale to new numbers of inputs and outputs without further evolution. HyperNEAT is demonstrated through visual discrimination and food-gathering tasks, including successful visual discrimination networks containing over eight million connections. The main conclusion is that the ability to explore the space of regular connectivity patterns opens up a new class of complex high-dimensional tasks to neuroevolution.},
annote = {The original HyperNEAT paper.},
author = {Stanley, Kenneth O and D'Ambrosio, David B and Gauci, Jason},
doi = {10.1162/artl.2009.15.2.15202},
file = {:home/lepisma/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stanley, D'Ambrosio, Gauci - 2009 - A hypercube-based encoding for evolving large-scale neural networks.pdf:pdf},
isbn = {1064-5462 (Print)$\backslash$r1064-5462 (Linking)},
issn = {1064-5462},
journal = {Artificial Life},
keywords = {Biological Evolution,Computational Biology,Food,HyperNEAT,Nerve Net,Nerve Net: metabolism,Visual Perception,Visual Perception: physiology},
number = {2},
pages = {185--212},
pmid = {19199382},
title = {{A hypercube-based encoding for evolving large-scale neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19199382},
volume = {15},
year = {2009}
}
@article{Stanley2007,
abstract = {Natural DNA can encode complexity on an enormous scale. Researchers are attempting to achieve the same representational efficiency in computers by implementing developmental encodings, i.e. encodings that map the genotype to the phenotype through a process of growth from a small starting point to a mature form. A major challenge in in this effort is to find the right level of abstraction of biological development to capture its essential properties without introducing unnecessary inefficiencies. In this paper, a novel abstraction of natural development, called Compositional Pattern Producing Networks (CPPNs), is proposed. Unlike currently accepted abstractions such as iterative rewrite systems and cellular growth simulations, CPPNs map to the phenotype without local interaction, that is, each individual component of the phenotype is determined independently of every other component. Results produced with CPPNs through interactive evolution of two dimensional images show that such an encoding can nevertheless produce structural motifs often attributed to more conventional developmental abstractions, suggesting that local interaction may not be essential to the desirable properties of natural encoding in the way that is usually assumed.},
author = {Stanley, Kenneth O.},
doi = {10.1007/s10710-007-9028-8},
isbn = {1389-2576},
issn = {13892576},
journal = {Genetic Programming and Evolvable Machines},
keywords = {Artificial embryogeny,Complexity,Developmental encoding,Evolutionary computation,Generative systems,Indirect encoding,Representation},
number = {2},
pages = {131--162},
title = {{Compositional pattern producing networks: A novel abstraction of development}},
volume = {8},
year = {2007}
}
@article{DeBrabandere2016,
abstract = {In a traditional convolutional layer, the learned filters stay fixed after training. In contrast, we introduce a new framework, the Dynamic Filter Network, where filters are generated dynamically conditioned on an input. We show that this architecture is a powerful one, with increased flexibility thanks to its adaptive nature, yet without an excessive increase in the number of model parameters. A wide variety of filtering operations can be learned this way, including local spatial transformations, but also others like selective (de)blurring or adaptive feature extraction. Moreover, multiple such layers can be combined, e.g. in a recurrent architecture. We demonstrate the effectiveness of the dynamic filter network on the tasks of video and stereo prediction, and reach state-of-the-art performance on the moving MNIST dataset with a much smaller model. By visualizing the learned filters, we illustrate that the network has picked up flow information by only looking at unlabelled training data. This suggests that the network can be used to pretrain networks for various supervised tasks in an unsupervised way, like optical flow and depth estimation.},
annote = {Papers to read:
1. Patraucean et al. [17]
2. Shi et: convolutional LSTM},
archivePrefix = {arXiv},
arxivId = {1605.09673},
author = {{De Brabandere}, Bert and Jia, Xu and Tuytelaars, Tinne and {Van Gool}, Luc},
eprint = {1605.09673},
file = {:home/lepisma/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Brabandere et al. - 2016 - Dynamic Filter Networks.pdf:pdf},
journal = {CoRR},
month = {may},
pages = {1--14},
title = {{Dynamic Filter Networks}},
url = {http://arxiv.org/abs/1605.09673},
year = {2016}
}
@article{Ha2016,
abstract = {This work explores hypernetworks: an approach of using a small network, also known as a hypernetwork, to generate the weights for a larger network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype - the hypernetwork - and a phenotype - the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve state-of-art results on a variety of language modeling tasks with Character-Level Penn Treebank and Hutter Prize Wikipedia datasets, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters.},
archivePrefix = {arXiv},
arxivId = {1609.09106},
author = {Ha, David and Dai, Andrew and Le, Quoc V.},
eprint = {1609.09106},
file = {:home/lepisma/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ha, Dai, Le - 2016 - HyperNetworks.pdf:pdf},
title = {{HyperNetworks}},
url = {http://arxiv.org/abs/1609.09106},
year = {2016}
}
@article{Stanley2009,
abstract = {Research in neuroevolution-that is, evolving artificial neural networks (ANNs) through evolutionary algorithms-is inspired by the evolution of biological brains, which can contain trillions of connections. Yet while neuroevolution has produced successful results, the scale of natural brains remains far beyond reach. This article presents a method called hypercube-based NeuroEvolution of Augmenting Topologies (HyperNEAT) that aims to narrow this gap. HyperNEAT employs an indirect encoding called connective compositional pattern-producing networks (CPPNs) that can produce connectivity patterns with symmetries and repeating motifs by interpreting spatial patterns generated within a hypercube as connectivity patterns in a lower-dimensional space. This approach can exploit the geometry of the task by mapping its regularities onto the topology of the network, thereby shifting problem difficulty away from dimensionality to the underlying problem structure. Furthermore, connective CPPNs can represent the same connectivity pattern at any resolution, allowing ANNs to scale to new numbers of inputs and outputs without further evolution. HyperNEAT is demonstrated through visual discrimination and food-gathering tasks, including successful visual discrimination networks containing over eight million connections. The main conclusion is that the ability to explore the space of regular connectivity patterns opens up a new class of complex high-dimensional tasks to neuroevolution.},
author = {Stanley, Kenneth O and D'Ambrosio, David B and Gauci, Jason},
doi = {10.1162/artl.2009.15.2.15202},
file = {:home/lepisma/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stanley, D'Ambrosio, Gauci - 2009 - A hypercube-based encoding for evolving large-scale neural networks.pdf:pdf},
isbn = {1064-5462 (Print)$\backslash$r1064-5462 (Linking)},
issn = {1064-5462},
journal = {Artificial Life},
keywords = {Biological Evolution,Computational Biology,Food,HyperNEAT,Nerve Net,Nerve Net: metabolism,Visual Perception,Visual Perception: physiology},
number = {2},
pages = {185--212},
pmid = {19199382},
title = {{A hypercube-based encoding for evolving large-scale neural networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19199382},
volume = {15},
year = {2009}
}
@article{Stanley2007,
abstract = {Natural DNA can encode complexity on an enormous scale. Researchers are attempting to achieve the same representational efficiency in computers by implementing developmental encodings, i.e. encodings that map the genotype to the phenotype through a process of growth from a small starting point to a mature form. A major challenge in in this effort is to find the right level of abstraction of biological development to capture its essential properties without introducing unnecessary inefficiencies. In this paper, a novel abstraction of natural development, called Compositional Pattern Producing Networks (CPPNs), is proposed. Unlike currently accepted abstractions such as iterative rewrite systems and cellular growth simulations, CPPNs map to the phenotype without local interaction, that is, each individual component of the phenotype is determined independently of every other component. Results produced with CPPNs through interactive evolution of two dimensional images show that such an encoding can nevertheless produce structural motifs often attributed to more conventional developmental abstractions, suggesting that local interaction may not be essential to the desirable properties of natural encoding in the way that is usually assumed.},
author = {Stanley, Kenneth O.},
doi = {10.1007/s10710-007-9028-8},
isbn = {1389-2576},
issn = {13892576},
journal = {Genetic Programming and Evolvable Machines},
keywords = {Artificial embryogeny,Complexity,Developmental encoding,Evolutionary computation,Generative systems,Indirect encoding,Representation},
number = {2},
pages = {131--162},
title = {{Compositional pattern producing networks: A novel abstraction of development}},
volume = {8},
year = {2007}
}
